{"title":"pytorch笔记——I","slug":"Pytorch1","date":"2020-07-26T07:59:44.000Z","updated":"2020-08-20T01:58:17.374Z","comments":true,"path":"api/articles/Pytorch1.json","photos":[],"link":"","excerpt":null,"covers":["https://img-blog.csdnimg.cn/20200820095246259.png#pic_center","https://img-blog.csdnimg.cn/20200820095338259.png#pic_center","https://img-blog.csdnimg.cn/202008200955034.png#pic_center","https://img-blog.csdnimg.cn/20200820095628379.png#pic_center","https://img-blog.csdnimg.cn/20200820093136233.png#pic_center","https://img-blog.csdnimg.cn/20200820095730991.png#pic_center","https://img-blog.csdnimg.cn/20200726224808698.png?","https://img-blog.csdnimg.cn/20200820094110441.png#pic_center","https://img-blog.csdnimg.cn/20200820094344736.png#pic_center","https://img-blog.csdnimg.cn/20200820094452573.png#pic_center","https://img-blog.csdnimg.cn/2020072622483447.png?"],"content":"<h1 id=\"Pytorch笔记1\"><a href=\"#Pytorch笔记1\" class=\"headerlink\" title=\"Pytorch笔记1\"></a>Pytorch笔记1</h1><h2 id=\"1-张量\"><a href=\"#1-张量\" class=\"headerlink\" title=\"1. 张量\"></a>1. 张量</h2><h3 id=\"1-1-张量的概念\"><a href=\"#1-1-张量的概念\" class=\"headerlink\" title=\"1.1 张量的概念\"></a>1.1 张量的概念</h3><p>​    张量是一个多维数组，是标量、向量、矩阵的多维拓展。可以说，标量是零维张量，向量是一维张量、矩阵是二维张量。在用Pytorch做机器学习时，一般要将数据转化成张量的形式。</p>\n<h3 id=\"1-2-张量的创建\"><a href=\"#1-2-张量的创建\" class=\"headerlink\" title=\"1.2 张量的创建\"></a>1.2 张量的创建</h3><h4 id=\"1-2-1-直接创建\"><a href=\"#1-2-1-直接创建\" class=\"headerlink\" title=\"1.2.1 直接创建\"></a>1.2.1 直接创建</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\">torch.tensor(</span><br><span class=\"line\">    data,</span><br><span class=\"line\">    dtype=<span class=\"literal\">None</span>,</span><br><span class=\"line\">    device=<span class=\"literal\">None</span>,</span><br><span class=\"line\">    requires_grad=<span class=\"literal\">False</span>,</span><br><span class=\"line\">    pin_memory=<span class=\"literal\">False</span></span><br><span class=\"line\">)</span><br></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>data</strong>: 数据, 可以是list, ndarray</li>\n<li><strong>dtype</strong> : 数据类型，默认与data的一致</li>\n<li><strong>device</strong> : 所在设备, cuda/cpu</li>\n<li><strong>requires_grad</strong>：是否需要梯度</li>\n<li><strong>pin_memory</strong>：是否存于锁页内存</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.from_numpy(ndarray)</span><br></pre></td></tr></table></figure>\n\n<p><strong>注</strong>：创建的张量和原来的ndarray共享内存，改变其中一个，另外一个也会改变。</p>\n<h4 id=\"1-2-2-依据数值创建\"><a href=\"#1-2-2-依据数值创建\" class=\"headerlink\" title=\"1.2.2 依据数值创建\"></a>1.2.2 依据数值创建</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.zeros(*size,</span><br><span class=\"line\">            out=<span class=\"literal\">None</span>,</span><br><span class=\"line\">            dtye=<span class=\"literal\">None</span>,</span><br><span class=\"line\">            layout=torch.strided,</span><br><span class=\"line\">            device=<span class=\"literal\">None</span>,</span><br><span class=\"line\">            requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：按照size创建全零张量</p>\n<ul>\n<li><strong>size</strong>: 张量的形状, 如(4, 4)、(4, 200,200)</li>\n<li><strong>out</strong> : 输出的张量</li>\n<li><strong>layout</strong> : 内存中布局形式, 有strided, sparse_coo等</li>\n<li><strong>device</strong> : 所在设备, gpu/cpu</li>\n<li><strong>requires_grad</strong>：是否需要梯度</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.zeros_like(input, </span><br><span class=\"line\">                 dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">                 layout=<span class=\"literal\">None</span>, </span><br><span class=\"line\">                 device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">                 requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：依照inout形状创建全零张量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.ones(*size, </span><br><span class=\"line\">           out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           layout=torch.strided, </span><br><span class=\"line\">           device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           requires_grad=<span class=\"literal\">False</span>）</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：按照size创建全一张量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.ones_like(input, </span><br><span class=\"line\">                dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">                layout=<span class=\"literal\">None</span>, </span><br><span class=\"line\">                device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">                requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：依照inout形状创建全一张量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.full(size, </span><br><span class=\"line\">           fill_value, <span class=\"comment\"># 指定数值</span></span><br><span class=\"line\">           out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           layout=torch.strided, </span><br><span class=\"line\">           device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：依照size的大小创建指定数值的张量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.arange(start=<span class=\"number\">0</span>, <span class=\"comment\"># 张量起始值</span></span><br><span class=\"line\">             end, <span class=\"comment\"># 张量结束值</span></span><br><span class=\"line\">             step=<span class=\"number\">1</span>, <span class=\"comment\"># 数列公差</span></span><br><span class=\"line\">             out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">             dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">             layout=torch.strided, </span><br><span class=\"line\">             device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">             requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：创建等差的一维张量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.linspace(start, <span class=\"comment\"># 数列起始值</span></span><br><span class=\"line\">               end, <span class=\"comment\"># 数列结束值</span></span><br><span class=\"line\">               steps=<span class=\"number\">100</span>, <span class=\"comment\"># 数列长度</span></span><br><span class=\"line\">               out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">               dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">               layout=torch.strided, </span><br><span class=\"line\">               device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">               requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：创建均分的一维张量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.logspace(start, </span><br><span class=\"line\">               end, </span><br><span class=\"line\">               steps=<span class=\"number\">100</span>, </span><br><span class=\"line\">               base=<span class=\"number\">10.0</span>, <span class=\"comment\"># 对数的底</span></span><br><span class=\"line\">               out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">               dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">               layout=torch.strided, </span><br><span class=\"line\">               device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">               requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：创建对数均分的一维张量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.eye(n, <span class=\"comment\"># 矩阵行数</span></span><br><span class=\"line\">          m=<span class=\"literal\">None</span>, <span class=\"comment\"># 矩阵列数</span></span><br><span class=\"line\">          out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">          dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">          layout=torch.strided, </span><br><span class=\"line\">          device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">          requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：创建单位对角矩阵</p>\n<h4 id=\"1-2-3-依照概率分布创建张量\"><a href=\"#1-2-3-依照概率分布创建张量\" class=\"headerlink\" title=\"1.2.3 依照概率分布创建张量\"></a>1.2.3 依照概率分布创建张量</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.normal(mean, <span class=\"comment\"># 均值</span></span><br><span class=\"line\">             std, <span class=\"comment\"># 标准差</span></span><br><span class=\"line\">             out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：生成正态分布(高斯分布)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.normal(mean, </span><br><span class=\"line\">             std, </span><br><span class=\"line\">             out=<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">torch.normal(mean, </span><br><span class=\"line\">             std, </span><br><span class=\"line\">             size, <span class=\"comment\"># 都为标量时可以指定数组的大小</span></span><br><span class=\"line\">             out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>四种可能出现的情况</strong>：</p>\n<p>mean为标量，std为标量</p>\n<p>mean为标量，std为张量</p>\n<p>mean为张量，std为标量</p>\n<p>mean为张量，std为张量</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.randn(*size, <span class=\"comment\"># 张量的形状</span></span><br><span class=\"line\">            out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">            dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">            layout=torch.strided, </span><br><span class=\"line\">            device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">            requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：生成标准正态分布</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.rand(*size, </span><br><span class=\"line\">           out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           layout=torch.strided, </span><br><span class=\"line\">           device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">torch.rand_like(input, </span><br><span class=\"line\">           out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           layout=torch.strided, </span><br><span class=\"line\">           device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">           requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：在区间[0,1)上生成均匀分布</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.randint(low=<span class=\"number\">0</span>, </span><br><span class=\"line\">              high, </span><br><span class=\"line\">              size, </span><br><span class=\"line\">              out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">              dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">              layout=torch.strided, </span><br><span class=\"line\">              device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">              requires_grad=<span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">torch.randint_like(low=<span class=\"number\">0</span>, </span><br><span class=\"line\">              high, </span><br><span class=\"line\">              input, </span><br><span class=\"line\">              out=<span class=\"literal\">None</span>, </span><br><span class=\"line\">              dtype=<span class=\"literal\">None</span>, </span><br><span class=\"line\">              layout=torch.strided, </span><br><span class=\"line\">              device=<span class=\"literal\">None</span>, </span><br><span class=\"line\">              requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：在区间[low,high)上生成均匀分布</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.randperm(n, <span class=\"comment\"># 张量的长度</span></span><br><span class=\"line\">               out=<span class=\"literal\">None</span>,</span><br><span class=\"line\">               dtype=torch.int64,</span><br><span class=\"line\">               layout=torch.strided,</span><br><span class=\"line\">               device=<span class=\"literal\">None</span>,</span><br><span class=\"line\">               requires_grad=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：生成0到n-1的随机排列</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.bernoulli(input, <span class=\"comment\"># 概率值</span></span><br><span class=\"line\">                *, </span><br><span class=\"line\">                generator=<span class=\"literal\">None</span>, </span><br><span class=\"line\">                out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：以inout为概率，生成伯努利分布(0,1分布，两点分布)</p>\n<h2 id=\"2-张量的操作和数学运算\"><a href=\"#2-张量的操作和数学运算\" class=\"headerlink\" title=\"2. 张量的操作和数学运算\"></a>2. 张量的操作和数学运算</h2><h3 id=\"2-1-张量的操作\"><a href=\"#2-1-张量的操作\" class=\"headerlink\" title=\"2.1 张量的操作\"></a>2.1 张量的操作</h3><h4 id=\"2-1-1-张量的拼接与切分\"><a href=\"#2-1-1-张量的拼接与切分\" class=\"headerlink\" title=\"2.1.1 张量的拼接与切分\"></a>2.1.1 张量的拼接与切分</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.cat(tensors, <span class=\"comment\"># 张量</span></span><br><span class=\"line\">          dim=<span class=\"number\">0</span>, <span class=\"comment\"># 拼接维度</span></span><br><span class=\"line\">          out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：将张量按照维度dim进行拼接</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.stack(tensors, </span><br><span class=\"line\">            dim=<span class=\"number\">0</span>, </span><br><span class=\"line\">            out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：在新创建的维度dim上进行拼接</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.chunk(input, <span class=\"comment\"># 输入的张量</span></span><br><span class=\"line\">            chunks, <span class=\"comment\"># 切分的份数</span></span><br><span class=\"line\">            dim=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：将张量按照维度dim进行平均切分</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.split(tensor, <span class=\"comment\"># 要切分的张量</span></span><br><span class=\"line\">            split_size_or_sections, <span class=\"comment\"># 为int时表示每一份的长度，为list时，按照list元素进行切分</span></span><br><span class=\"line\">            dim=<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n\n<h4 id=\"2-1-2-张量索引\"><a href=\"#2-1-2-张量索引\" class=\"headerlink\" title=\"2.1.2 张量索引\"></a>2.1.2 张量索引</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.index_select(input, <span class=\"comment\"># 要索引的张量</span></span><br><span class=\"line\">                   dim,  <span class=\"comment\"># 要索引的维度</span></span><br><span class=\"line\">                   index, <span class=\"comment\"># 要索引数据的序号</span></span><br><span class=\"line\">                   out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：在维度dim上，按照index索引数据</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.masked_select(input, <span class=\"comment\"># 要索引的张量</span></span><br><span class=\"line\">                    mask, <span class=\"comment\"># 与张量同类型的布尔类型张量</span></span><br><span class=\"line\">                    out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：按照mask中的True进行索引</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.reshape(input, </span><br><span class=\"line\">              shape) <span class=\"comment\"># 新张量的形状</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：变化张量的形状，注：当张量在内存中是连续时，新张量与input共享数据内存</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.transpose(input, <span class=\"comment\"># 输入的张量</span></span><br><span class=\"line\">                dim0, <span class=\"comment\"># 要交换的维度</span></span><br><span class=\"line\">                dim1) <span class=\"comment\"># 要交换的维度</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：交换张量的两个维度</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.t(input)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：二维张量转置</p>\n<h4 id=\"2-1-3-张量变换\"><a href=\"#2-1-3-张量变换\" class=\"headerlink\" title=\"2.1.3 张量变换\"></a>2.1.3 张量变换</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.squeeze(input, </span><br><span class=\"line\">              dim=<span class=\"literal\">None</span>, </span><br><span class=\"line\">              out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：压缩长度为1的维度</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.usqueeze(input, </span><br><span class=\"line\">               dim, <span class=\"comment\"># 拓展的维度</span></span><br><span class=\"line\">               out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：按照dim创造维度</p>\n<h3 id=\"2-2-张量的数学运算\"><a href=\"#2-2-张量的数学运算\" class=\"headerlink\" title=\"2.2 张量的数学运算\"></a>2.2 张量的数学运算</h3><p><strong>加减乘除</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.add()</span><br><span class=\"line\">torch.addcdiv()</span><br><span class=\"line\">torch.addcmul()</span><br><span class=\"line\">torch.sub()</span><br><span class=\"line\">torch.div()</span><br><span class=\"line\">torch.mul()</span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.add(input, <span class=\"comment\"># 第一个张量</span></span><br><span class=\"line\">          alpha=<span class=\"number\">1</span>, <span class=\"comment\"># 乘项因子</span></span><br><span class=\"line\">          other, <span class=\"comment\"># 第二个张量</span></span><br><span class=\"line\">          out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：逐元素加法计算</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200820095246259.png#pic_center\" alt></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.addcmul(input, <span class=\"comment\"># 第一个张量</span></span><br><span class=\"line\">              value=<span class=\"number\">1</span>, <span class=\"comment\"># 乘项因子</span></span><br><span class=\"line\">              tensor1, <span class=\"comment\"># 第二个张量</span></span><br><span class=\"line\">              tensor2, <span class=\"comment\"># 第三个张量</span></span><br><span class=\"line\">              out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：逐元素计算</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200820095338259.png#pic_center\" alt></p>\n<p><strong>对数、指数、幂函数</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.log(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.log10(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.log2(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.exp(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.pow()</span><br></pre></td></tr></table></figure>\n\n<p><strong>三角函数</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.abs(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.acos(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.cosh(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.cos(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.asin(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.atan(input, out=<span class=\"literal\">None</span>)</span><br><span class=\"line\">torch.atan2(input, other, out=<span class=\"literal\">None</span>)</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"3-计算图\"><a href=\"#3-计算图\" class=\"headerlink\" title=\"3.计算图\"></a>3.计算图</h2><h3 id=\"3-1-计算图的概念\"><a href=\"#3-1-计算图的概念\" class=\"headerlink\" title=\"3.1 计算图的概念\"></a>3.1 计算图的概念</h3><p><strong>计算图</strong>是用来描述运算的有向无环图。计算图有两个主要元素：<strong>节点</strong>和<strong>边</strong>，结点表示数据，如向量，矩阵，张量</p>\n<p>边表示运算，如加减乘除卷积等</p>\n<p>叶子节点：用户创建的节点是叶子节点，就是输入的数据</p>\n<h3 id=\"3-2-静态图和动态图\"><a href=\"#3-2-静态图和动态图\" class=\"headerlink\" title=\"3.2 静态图和动态图\"></a>3.2 静态图和动态图</h3><p><strong>静态图</strong>：先搭建图，后运算      <strong>特点</strong>：高效但不灵活      <strong>代表框架</strong>：Tensorflow</p>\n<p><strong>动态图</strong>：运算与搭建同时进行      <strong>特点</strong>：灵活、易于调节      <strong>代表框架</strong>：Pytorch</p>\n<h2 id=\"4-autograd\"><a href=\"#4-autograd\" class=\"headerlink\" title=\"4.autograd\"></a>4.autograd</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.autograd.backward(tensors,<span class=\"comment\"># 用于求导的张量，如loss</span></span><br><span class=\"line\">                        grad_tensors=<span class=\"literal\">None</span>, <span class=\"comment\"># 多梯度权重</span></span><br><span class=\"line\">                        retain_graph=<span class=\"literal\">None</span>, <span class=\"comment\"># 保存计算图</span></span><br><span class=\"line\">                        create_graph=<span class=\"literal\">False</span>) <span class=\"comment\"># 创建导数计算图，用于高阶求导</span></span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：自动求取梯度</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">torch.autograd.grad(outputs, <span class=\"comment\"># 用于求导的张量，如loss</span></span><br><span class=\"line\">                    inputs, <span class=\"comment\"># 需要梯度的张量</span></span><br><span class=\"line\">                    grad_outputs=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                    retain_graph=<span class=\"literal\">None</span>,</span><br><span class=\"line\">                    create_graph=<span class=\"literal\">False</span>)</span><br></pre></td></tr></table></figure>\n\n<p><strong>功能</strong>：自动求取梯度</p>\n<p><strong>注意</strong>：1.梯度不自动清零，每次求取完后需要手动清零</p>\n<p>​            2.依赖于叶子结点的结点，requires_grad默认为True</p>\n<p>​            3.叶子结点不可执行in-place(原位操作：在原来的内存上改变变量的值)</p>\n<h2 id=\"5-线性回归与逻辑回归\"><a href=\"#5-线性回归与逻辑回归\" class=\"headerlink\" title=\"5.线性回归与逻辑回归\"></a>5.线性回归与逻辑回归</h2><h3 id=\"5-1-线性回归\"><a href=\"#5-1-线性回归\" class=\"headerlink\" title=\"5.1 线性回归\"></a>5.1 线性回归</h3><p>线性回归是分析一个变量(<strong>因变量</strong>)与另外一个或多个变量(<strong>自变量</strong>)之间的<strong>线性</strong>关系的方法。例如：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/202008200955034.png#pic_center\" alt></p>\n<p><strong>求解步骤</strong>：</p>\n<ul>\n<li><p>确定模型</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200820095628379.png#pic_center\" alt></p>\n</li>\n<li><p>选择损失函数</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200820093136233.png#pic_center\" alt></p>\n</li>\n<li><p>求解梯度并更新w,b</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200820095730991.png#pic_center\" alt></p>\n</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/20200726224808698.png?\" alt></p>\n<h3 id=\"5-2-逻辑回归\"><a href=\"#5-2-逻辑回归\" class=\"headerlink\" title=\"5.2 逻辑回归\"></a>5.2 逻辑回归</h3><p>逻辑回归是<strong>线性</strong>的<strong>二分类</strong>模型,</p>\n<p><strong>模型表达式</strong>：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200820094110441.png#pic_center\" alt></p>\n<p>f(x)称为sigmoid函数</p>\n<p><strong>分类标准</strong>：</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200820094344736.png#pic_center\" alt></p>\n<p>线性回归是分析自变量x与因变量y(<strong>标量</strong>)之间关系的方法</p>\n<p>逻辑回归是分析自变量x与因变量y(<strong>概率</strong>)之间关系的方法</p>\n<p><strong>推导</strong>：由对数几率回归</p>\n<p><img src=\"https://img-blog.csdnimg.cn/20200820094452573.png#pic_center\" alt></p>\n<p><img src=\"https://img-blog.csdnimg.cn/2020072622483447.png?\" alt></p>\n","categories":[],"tags":[]}